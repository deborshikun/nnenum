#!/usr/bin/env python3
"""
Automation loop to:
 1) For each rule in an explanation file, calculate the "gaps" between the rule's bounds
    and the original, wider input bounds from a base vnnlib file.
 2) Create a temporary vnnlib file that asserts the input must lie within these gaps,
    while also keeping the original safety property.
 3) Run nnenum to check if any input in these gaps leads to a safety violation (a counterexample).
 4) If a counterexample is found, read the corresponding output from the file generated by nnenum,
    then feed all this data back to Gemini to produce a new, refined bounds file, and repeat.
"""

import argparse
import os
import re
import subprocess
import sys
import time
from pathlib import Path
from typing import List, Tuple, Optional, Dict


# Optional Gemini import; error handled at call time
try:
    import google.generativeai as genai  # type: ignore
except Exception:
    genai = None  # type: ignore

# ---------------------- Data Structures ----------------------
Interval = Tuple[float, float]
VarBounds = Dict[int, Interval]

# ---------------------- Parsing Utilities ----------------------
BOUND_RE = re.compile(r"\(\s*([<>]=)\s+X_(\d+)\s+([-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)\s*\)")
INDEP_RE = re.compile(r"^\s*X_(?P<var>\d+)\s+belongs\s+to\s+(?P<intervals>.+?)\s*$", re.IGNORECASE)
INTERVAL_RE = re.compile(r"\[\s*(?P<a>[-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)\s*,\s*(?P<b>[-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)\s*\]")


def parse_base_vnnlib_bounds(vnnlib_text: str) -> VarBounds:
    """Parses a VNNLIB file content to extract the simple input bounds for each X_i variable."""
    bounds: Dict[int, Dict[str, float]] = {}
    for match in BOUND_RE.finditer(vnnlib_text):
        op, var_idx_str, val_str = match.groups()
        var_idx = int(var_idx_str)
        val = float(val_str)
        if var_idx not in bounds:
            bounds[var_idx] = {'min': -float('inf'), 'max': float('inf')}
        if op == '>=':
            bounds[var_idx]['min'] = max(bounds[var_idx]['min'], val)
        elif op == '<=':
            bounds[var_idx]['max'] = min(bounds[var_idx]['max'], val)
    final_bounds: VarBounds = {}
    for var_idx, b in bounds.items():
        if b['min'] > -float('inf') and b['max'] < float('inf'):
            final_bounds[var_idx] = (b['min'], b['max'])
    return final_bounds


def parse_explanation_intervals(text: str) -> List[Interval]:
    """Parse intervals from a string like "[a,b] OR [c,d] OR ..."""
    intervals: List[Interval] = []
    for m in INTERVAL_RE.finditer(text):
        a = float(m.group("a"))
        b = float(m.group("b"))
        if a > b: a, b = b, a
        intervals.append((a, b))
    return intervals


def parse_explanation_line(line: str) -> Optional[Dict]:
    """Parses a single line of the explanation text file."""
    line = line.strip()
    if not line or line.startswith('#') or line.startswith(';'): return None
    m = INDEP_RE.match(line)
    if m:
        var = int(m.group('var'))
        ivals = parse_explanation_intervals(m.group('intervals'))
        if not ivals: raise ValueError(f"No intervals parsed in independent bound line: '{line}'")
        return {'var': var, 'intervals': ivals, 'raw': line}
    if "when" in line.lower():
        print(f"Warning: Skipping dependent rule (not yet supported in this strategy): {line}")
        return None
    return None


def parse_vector_from_file_content(text: str) -> Optional[List[float]]:
    """Parses a vector from a file containing text like '[v1, v2, ...]'."""
    m = re.search(r"\[([^\]]+)\]", text)
    if not m: return None
    try:
        return [float(p.strip()) for p in m.group(1).split(',')]
    except (ValueError, IndexError):
        return None

# ---------------------- Logic for Bound Difference ----------------------

def calculate_bound_difference(original_bound: Interval, llm_intervals: List[Interval]) -> List[Interval]:
    """Calculates the gaps: parts of original_bound NOT covered by llm_intervals."""
    orig_min, orig_max = original_bound
    if not llm_intervals: return [original_bound]
    llm_intervals.sort()
    merged = [llm_intervals[0]]
    for current_min, current_max in llm_intervals[1:]:
        last_min, last_max = merged[-1]
        if current_min <= last_max:
            merged[-1] = (last_min, max(last_max, current_max))
        else:
            merged.append((current_min, current_max))
    gaps: List[Interval] = []
    current_pos = orig_min
    for llm_min, llm_max in merged:
        if current_pos < llm_min:
            gaps.append((current_pos, llm_min))
        current_pos = max(current_pos, llm_max)
    if current_pos < orig_max:
        gaps.append((current_pos, orig_max))
    return [(a, b) for a, b in gaps if (b - a) > 1e-9]

def vnnlib_and_inside(var_index: int, interval: Interval) -> str:
    """Generates a VNNLIB string for X_i being inside an interval."""
    a, b = interval
    return f"(and (>= X_{var_index} {a}) (<= X_{var_index} {b}))"

# ---------------------- nnenum execution ----------------------
def run_nnenum(repo_root: Path, onnx_path: Path, vnnlib_path: Path, timeout: int, outfile: Path) -> str:
    """Run nnenum and return combined stdout+stderr as text."""
    # --- Windows (PowerShell) Execution ---
    ps_cmd = (
        '$env:OPENBLAS_NUM_THREADS="1"; '
        '$env:OMP_NUM_THREADS="1"; '
        '$env:MKL_NUM_THREADS="1"; '
        '$env:NUMEXPR_NUM_THREADS="1"; '
        '$env:PYTHONPATH=(Resolve-Path ./src).Path; '
        f'python -m nnenum.nnenum "{onnx_path}" "{vnnlib_path}" {timeout} "{outfile}"'
    )
    res = subprocess.run(
        ['powershell', '-NoProfile', '-Command', ps_cmd],
        cwd=str(repo_root), capture_output=True, text=True, encoding='utf-8'
    )
    return (res.stdout or '') + '\n' + (res.stderr or '')

# ---------------------- Gemini call for Refinement ----------------------

def ensure_gemini(api_key: Optional[str]):
    if genai is None:
        raise RuntimeError("google-generativeai is not installed. Run: pip install google-generativeai")
    if not api_key:
        raise RuntimeError("Gemini API key missing. Pass --api-key or set GEMINI_API_KEY env var.")
    genai.configure(api_key=api_key)

def call_gemini_to_refine_bounds(
    api_key: str, model_name: str, base_adv_lines: List[str],
    new_counterexamples: List[List[float]], prev_bounds_text: str
) -> str:
    """Call Gemini to refine bounds based on new counterexamples."""
    ensure_gemini(api_key)
    model = genai.GenerativeModel(model_name)
    header = (
        "Refine the 'Previous bounds' below using the newly found counterexamples. "
        "The goal is to make the bounds tighter or more accurate so they no longer include the counterexamples. "
        "Preserve the original format exactly. Do not include any commentary.\n\n"
        "FORMAT EXAMPLES:\n"
        "X_1 belongs to [1,2]\n"
        "X_2 belongs to [2,3] OR [1,2]\n\n"
        "ONLY output lines in this exact format."
    )
    cex_section = ["Newly found counterexamples (these inputs are unsafe):"]
    for vec in new_counterexamples:
        assignments = ", ".join(f"X_{i}={v}" for i, v in enumerate(vec))
        cex_section.append(assignments)
    
    parts = [header, "Previous bounds:\n" + prev_bounds_text.strip(), "\n".join(cex_section)]
    if base_adv_lines:
        orig_adv_section = ["Original adversarial inputs (for context):"] + base_adv_lines
        parts.append("\n".join(orig_adv_section))

    full_prompt = "\n\n".join(parts)
    resp = model.generate_content(full_prompt)
    try:
        text = "\n".join([p.text for c in resp.candidates for p in c.content.parts])
        return text.strip()
    except Exception:
        raise RuntimeError("Gemini response had no text content")

# ---------------------- Main loop ----------------------

def main():
    parser = argparse.ArgumentParser(description="Automate LLM-vs-nnenum loop using gap analysis.")
    parser.add_argument('--api-key', default=os.getenv('GEMINI_API_KEY'), help='Gemini API key.')
    parser.add_argument('--gemini-model', default='gemini-1.5-pro-latest', help='Gemini model name.')
    parser.add_argument('--onnx', required=True, help='Path to ONNX network file.')
    parser.add_argument('--base-vnnlib', required=True, help='Path to base vnnlib property file.')
    parser.add_argument('--explanation', required=True, help='Path to the initial explanation file.')
    parser.add_argument('--adv-inputs', required=True, help='Path to the adversarial inputs text file.')
    parser.add_argument('--timeout', type=int, default=60, help='nnenum timeout seconds.')
    parser.add_argument('--iterations', type=int, default=3, help='Max loop iterations.')
    parser.add_argument('--output-dir', default='automation_output', help='Directory for generated files.')
    args = parser.parse_args()

    # --- File setup ---
    repo_root = Path(__file__).resolve().parents[1]
    onnx_path = Path(args.onnx)
    out_dir = Path(args.output_dir).resolve()
    out_dir.mkdir(parents=True, exist_ok=True)
    
    base_vnnlib_text = Path(args.base_vnnlib).read_text(encoding='utf-8')
    original_input_bounds = parse_base_vnnlib_bounds(base_vnnlib_text)
    print("--- Parsed Original Input Bounds ---")
    for var, (vmin, vmax) in sorted(original_input_bounds.items()):
        print(f"  X_{var}: [{vmin}, {vmax}]")
    print("-" * 34)
    
    # --- Main Loop ---
    current_explanation_path = Path(args.explanation)
    all_found_cex: List[List[float]] = []

    for iteration in range(args.iterations):
        print(f"\n--- Starting Iteration {iteration} ---")
        if not current_explanation_path.exists():
            print(f"ERROR: Explanation file not found: {current_explanation_path}. Stopping.")
            break
        
        explanation_text = current_explanation_path.read_text(encoding='utf-8')
        explanation_lines = explanation_text.splitlines()
        new_cex_this_iteration: List[List[float]] = []
        
        for i, line in enumerate(explanation_lines):
            parsed_rule = parse_explanation_line(line)
            if not parsed_rule: continue

            var_idx = parsed_rule['var']
            if var_idx not in original_input_bounds:
                print(f"Warning: No original bounds for X_{var_idx} in rule: '{line.strip()}'")
                continue

            gaps = calculate_bound_difference(original_input_bounds[var_idx], parsed_rule['intervals'])
            if not gaps:
                print(f"  Rule {i+1} for X_{var_idx} has no gaps. Skipping.")
                continue
            
            gap_conditions = " ".join(vnnlib_and_inside(var_idx, gap) for gap in gaps)
            gap_assertion = f"(assert (or {gap_conditions}))"
            tmp_vnnlib_path = out_dir / f"iter{iteration}_rule{i+1}_gaps.vnnlib"
            with tmp_vnnlib_path.open('w', encoding='utf-8') as f:
                f.write(base_vnnlib_text)
                f.write(f"\n\n; --- Gap analysis for rule: {line.strip()} ---\n")
                f.write(gap_assertion + "\n")
            
            print(f"  Testing gaps for rule {i+1}: X_{var_idx} -> {tmp_vnnlib_path.name}")
            outfile_path = out_dir / f"result_iter{iteration}_rule{i+1}.txt"
            output_text = run_nnenum(repo_root, onnx_path, tmp_vnnlib_path, args.timeout, outfile_path)
            
            cex_input = parse_vector_from_file_content(output_text)
            if cex_input:
                # --- NEW: Read output from the .coutput file ---
                coutput_path = outfile_path.with_suffix('.coutput')
                output_vector = None
                if coutput_path.exists():
                    output_text_from_file = coutput_path.read_text(encoding='utf-8')
                    output_vector = parse_vector_from_file_content(output_text_from_file)

                # --- NEW: Formatted printing with input and output ---
                formatted_input = ", ".join(f"X_{i}={v:.6f}" for i, v in enumerate(cex_input))
                print(f"    -> CEX FOUND: Input:  {formatted_input}")
                if output_vector:
                    formatted_output = ", ".join(f"Y_{i}={v:.6f}" for i, v in enumerate(output_vector))
                    print(f"                 Output: {formatted_output}")

                new_cex_this_iteration.append(cex_input)
            
            time.sleep(1)

        if not new_cex_this_iteration:
            print("\n--- VERIFICATION SUCCESS ---")
            print("No counterexamples found in any gaps. The rules are robust.")
            break
            
        all_found_cex.extend(new_cex_this_iteration)
        
        # --- Refinement Step ---
        print("\n--- Refinement Step ---")
        print(f"Found {len(new_cex_this_iteration)} new counterexample(s). Asking Gemini to refine...")
        try:
            base_adv_lines = Path(args.adv_inputs).read_text(encoding='utf-8').splitlines()
            refined_text = call_gemini_to_refine_bounds(
                args.api_key, args.gemini_model, base_adv_lines, all_found_cex, explanation_text
            )
            
            next_explanation_path = out_dir / f"New Bounds {iteration + 1}.txt"
            next_explanation_path.write_text(refined_text + '\n', encoding='utf-8')
            print(f"Wrote refined explanation to: {next_explanation_path}")
            current_explanation_path = next_explanation_path
        except Exception as e:
            print(f"ERROR: Gemini refinement call failed: {e}", file=sys.stderr)
            print("Stopping loop due to LLM error.")
            break

    print("\nDone.")

if __name__ == '__main__':
    main()